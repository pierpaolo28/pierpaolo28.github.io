---
layout: post_book
date: 2020-10-12
---

Nowadays Machine Learning models, makes use of correlations between the different dataset features in order to try to understand how these are related to each other in order to then create a model able to accurately summarise how the data generative process works. This type of approach has been demonstrated to be quite effective in some applications, although not in **causality** driven systems. In fact, correlations do not necessarily imply causations and this can lead to biased models which make wrong assumptions about how different aspects of a system are connected to each other. Embedding causal reasoning in Machine Learning models would then enable us to create models which can have much greater general use (avoiding overfitting) and which do not rely on training on large amount of data. In [The Book of Why](https://amzn.to/2X8AFrI){:target="_blank"} we therefore find out about the importance of causality in order to build truly general AI systems.

<!--end_excerpt-->

## Takeaway Points

1. Causality was originally disregarded not as a real science (pseudoscience), but we are instead now able to express causality in a Mathematical Language.
2. Data alone is not the solution. If causality is not taken into account, this can lead to wrong conclusions.
3. Our Journey into causal reasoning can be divided into 3 main levels: **association**, **intervention** and **counterfactuals**.
4. At the association level we are able to answer questions such as **How would change X, affect Y?**. At the intervention level, we can instead answer also questions such as **What if?**. Finally, at the counterfactuals level we are instead able to try to answer retrospective questions such as: **What would have happened if I acted differently?**.
5. In order to demonstrate causality, we need to be able to control **confounders** and identify **mediator** variables.

## Quotes

> "Causality has been mathematized."

> "Virgil first proclaimed: Lucky is he who has been able to understand the causes of things (29 BC.)"

> "My emphasis on language also comes from a deep conviction that language shapes our thoughts. You cannot answer a question that you cannot ask, and you cannot ask a question that you have no words for."

> "That's all that a deep-learning program can do: fit a function to data."

> "If I could sum up the message of this book in one tiny phrase, it would be that you are smarter than your data. Data do not understand causes and effects; humans do."

Book Authors: Judea Pearl and Dana Mackenzie
